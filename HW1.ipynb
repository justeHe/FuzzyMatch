{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                   NAME\n",
      "0   36         AERO-CARIBBEAN\n",
      "1  173            AVIA IMPORT\n",
      "2  306  NATIONAL BANK OF CUBA\n",
      "3  540                  COIBA\n",
      "4  552                 CRYMSA\n",
      "    ID                       NAME TYPE\n",
      "0   36     AEROCARIBBEAN AIRLINES    C\n",
      "1  173  ANGLO-CARIBBEAN CO., LTD.    C\n",
      "2  306     BANCO NACIONAL DE CUBA    C\n",
      "3  424         BOUTIQUE LA MAISON    C\n",
      "4  475               CASA DE CUBA    C\n",
      "    ID                   VARIANT\n",
      "0   36     AEROCARIBEA NAIRLINES\n",
      "1  173  UNGLO-CARIBBEAN CO., LT.\n",
      "2  306    BANCO NACIONAL DE gUBA\n",
      "3  424       BOUTIQUE# LA MAISON\n",
      "4  475               CASA E CUBA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML/lib/python3.13/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the data\n",
    "#只载入前1000行\n",
    "alternate_names = pd.read_csv('alternate.csv')\n",
    "primary_names = pd.read_csv('primary.csv')\n",
    "test_names = pd.read_csv('test_01.csv')\n",
    "print(alternate_names.head())\n",
    "print(primary_names.head())\n",
    "print(test_names.head())\n",
    "\n",
    "#Number Maps\n",
    "number_map = {'0': ['zero', 'o'], \n",
    "              '1': ['one','|','i','l'], \n",
    "              '2': ['two', 'z', 'ii'],\n",
    "              '3': ['three', 'iii'],\n",
    "              '4': ['four', 'iv'], \n",
    "              '5': ['five', 's', 'v'], \n",
    "              '6': ['six', 'vi'],\n",
    "              '7': ['seven', 'vii'],\n",
    "              '8': ['eight', 'viii'],\n",
    "              '9': ['nine', 'ix']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:10<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 93.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fuzzy_match_test_to_primary(test_names, primary_names):\n",
    "    correct_matches = 0 \n",
    "    total_tests = len(test_names) \n",
    "    for _, test_row in tqdm(test_names.iterrows(), total=total_tests):\n",
    "        test_id = test_row['ID']\n",
    "        test_variant = test_row['VARIANT']\n",
    "\n",
    "        match, score, _ = process.extractOne(test_variant, primary_names['NAME'])\n",
    "\n",
    "        matched_row = primary_names[primary_names['NAME'] == match]\n",
    "        matched_id = matched_row['ID'].values[0]\n",
    "\n",
    "        if matched_id == test_id:\n",
    "            correct_matches += 1\n",
    "\n",
    "    accuracy = correct_matches / total_tests\n",
    "    return accuracy\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = fuzzy_match_test_to_primary(test_names, primary_names)\n",
    "print(f\"准确率: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "匹配进度: 100%|██████████| 16041/16041 [01:52<00:00, 143.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 93.69%\n",
      "匹配结果已保存到 matched_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载数据\n",
    "alternate_names = pd.read_csv('alternate.csv')\n",
    "primary_names = pd.read_csv('primary.csv')\n",
    "test_names = pd.read_csv('test_01.csv')\n",
    "\n",
    "# 准备 primary name 列表\n",
    "primary_names_list = primary_names['NAME'].tolist()\n",
    "primary_ids = primary_names['ID'].tolist()\n",
    "\n",
    "# 匹配函数\n",
    "def match_test_variant(test_row):\n",
    "    test_id = test_row['ID']\n",
    "    test_variant = test_row['VARIANT']\n",
    "\n",
    "    match, score, _ = process.extractOne(\n",
    "        test_variant, \n",
    "        primary_names_list, \n",
    "        scorer=fuzz.token_sort_ratio\n",
    "    )\n",
    "\n",
    "    matched_index = primary_names_list.index(match)\n",
    "    matched_id = primary_ids[matched_index]\n",
    "\n",
    "    return {\n",
    "        'test_id': test_id,\n",
    "        'test_variant': test_variant,\n",
    "        'matched_id': matched_id,\n",
    "        'matched_name': match,\n",
    "        'score': score,\n",
    "        'is_correct': int(test_id == matched_id)\n",
    "    }\n",
    "\n",
    "# 并行处理并收集结果\n",
    "def fuzzy_match_test_to_primary(test_names):\n",
    "    matched_results = []\n",
    "    total_tests = len(test_names)\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(match_test_variant, row) for row in test_names.to_dict('records')]\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=total_tests, desc=\"匹配进度\"):\n",
    "            result = future.result()\n",
    "            matched_results.append(result)\n",
    "\n",
    "    return matched_results\n",
    "\n",
    "# 执行匹配\n",
    "results = fuzzy_match_test_to_primary(test_names)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = results_df['is_correct'].sum() / len(results_df)\n",
    "print(f\"准确率: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 保存为 CSV\n",
    "results_df.to_csv('./Matched_results/Test1_matched_results.csv', index=False)\n",
    "print(\"匹配结果已保存到 matched_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16041, 3)\n",
      "找到 16017 个唯一代表项（精确匹配）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模糊聚类中:  97%|█████████▋| 15525/16017 [02:05<00:03, 123.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 高分（>98）错误匹配列表 ===\n",
      "Base(ID=26466, NAME='SMILE PROPERTY & TRAVEL LTD')  <->  Other(ID=26603, NAME='SMILE PROPERTY & TRAVEL LTD.')  |  score=98.18181818181819\n",
      "Base(ID=43125, NAME='SEVERNAYA ZVEZDA LIMITED LIABILITY COMPANY')  <->  Other(ID=49147, NAME='LIMITED LIABILITY COMPANY SEVERNAYA ZVEZDA')  |  score=100.0\n",
      "Base(ID=44264, NAME='NAI ENERGY EUROPE GMBH & CO. KG')  <->  Other(ID=44270, NAME='NAI EUROPE ENERGY GMBH & CO. KG')  |  score=100.0\n",
      "Base(ID=46022, NAME='LIMITED LIABILITY COMPANY KISMET TELECOM INFRASTRUCTURE')  <->  Other(ID=46028, NAME='LIMITED LIABILITY COMPANY KISMET TELECOM INFRASTRUCTURE 2')  |  score=98.21428571428571\n",
      "Base(ID=50016, NAME='FEDERAL STATE GOVERNMENTAL INSTITUTION 4 CENTRAL RESEARCH INSTITUTE OF THE MINISTRY OF DEFENSE OF THE RUSSIAN FEDERATION')  <->  Other(ID=50017, NAME='FEDERAL STATE GOVERNMENTAL INSTITUTION 27 CENTRAL RESEARCH INSTITUTE OF THE MINISTRY OF DEFENSE OF THE RUSSIAN FEDERATION')  |  score=98.7551867219917\n",
      "Base(ID=6706, NAME='ARELLANO FELIX, Ramon Eduardo')  <->  Other(ID=8234, NAME='ARELLANO FELIX, Eduardo Ramon')  |  score=100.0\n",
      "\n",
      "去重准确率（含精确+模糊）: 0.0000\n",
      "压缩比: 0.9678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "# 简单清洗函数：统一大小写 + 去除非字母数字\n",
    "def clean_name(name):\n",
    "    return re.sub(r'[^a-zA-Z0-9 ]', '', name.lower())\n",
    "\n",
    "def deduplicate_exact_then_fuzzy(df, threshold=90, high_score_cutoff=98):\n",
    "    df = df.copy()\n",
    "    # --- Step 1: 完全重复的清洗 ---\n",
    "    exact_groups = {}\n",
    "    print(df.shape)\n",
    "    for _, row in df.iterrows():\n",
    "        clean = row['NAME']\n",
    "        if clean not in exact_groups:\n",
    "            exact_groups[clean] = [row.to_dict()]\n",
    "        else:\n",
    "            exact_groups[clean].append(row.to_dict())\n",
    "\n",
    "    # 从 exact_groups 中提取未归组的代表项（每组取第一个代表进入模糊匹配）\n",
    "    unique_representatives = [group[0] for group in exact_groups.values()]\n",
    "    print(f\"找到 {len(unique_representatives)} 个唯一代表项（精确匹配）\")\n",
    "    ungrouped = unique_representatives.copy()\n",
    "\n",
    "    # --- Step 2: 模糊聚类 ---\n",
    "    grouped = []\n",
    "    total_matches = 0\n",
    "    wrong_matches = 0\n",
    "    compress = 0\n",
    "\n",
    "    # 用来收集高分但错误的匹配\n",
    "    high_score_errors = []\n",
    "\n",
    "    pbar = tqdm(total=len(ungrouped), desc=\"模糊聚类中\")\n",
    "\n",
    "    while ungrouped:\n",
    "        base = ungrouped.pop(0)\n",
    "        base_clean = base['NAME']\n",
    "        base_group = [base]\n",
    "        to_remove = []\n",
    "\n",
    "        # 收集本轮内所有“匹配”对，用于后续筛选错误时查分数\n",
    "        match_pairs = []\n",
    "\n",
    "        for other in ungrouped:\n",
    "            other_clean = other['NAME']\n",
    "            score = fuzz.token_sort_ratio(base_clean, other_clean)\n",
    "            if score >= threshold:\n",
    "                base_group.append(other)\n",
    "                to_remove.append(other)\n",
    "                match_pairs.append((base, other, score))\n",
    "\n",
    "        # 聚合同 base_clean 相同的所有 exact group 成员\n",
    "        final_group = []\n",
    "        for item in base_group:\n",
    "            final_group.extend(exact_groups[item['NAME']])\n",
    "\n",
    "        # 统计错误匹配：用最短名字的 ID 为标准\n",
    "        compress += 1\n",
    "        total_matches += len(final_group) - 1\n",
    "        shortest_item = min(final_group, key=lambda x: len(x['NAME']))\n",
    "        representative_id = shortest_item['ID']\n",
    "\n",
    "        # 遍历所有 match_pairs，找出那些实际被分在一起但 ID != representative_id 的高级错误\n",
    "        for a, b, score in match_pairs:\n",
    "            # 找到它们在 final_group 中的所有原始条目\n",
    "            entries = exact_groups[b['NAME']]\n",
    "            for entry in entries:\n",
    "                if entry['ID'] != representative_id and score > high_score_cutoff:\n",
    "                    high_score_errors.append({\n",
    "                        'base_ID': base['ID'],\n",
    "                        'base_NAME': base['NAME'],\n",
    "                        'other_ID': entry['ID'],\n",
    "                        'other_NAME': entry['NAME'],\n",
    "                        'score': score\n",
    "                    })\n",
    "\n",
    "        # 统计错误数\n",
    "        wrong_in_group = sum(1 for item in final_group if item['ID'] != representative_id)\n",
    "        wrong_matches += wrong_in_group\n",
    "\n",
    "        grouped.append(final_group)\n",
    "\n",
    "        # 移除已归组成员\n",
    "        ungrouped = [u for u in ungrouped if u not in to_remove]\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # 打印出 score > high_score_cutoff 的错误匹配\n",
    "    if high_score_errors:\n",
    "        print(f\"\\n=== 高分（>{high_score_cutoff}）错误匹配列表 ===\")\n",
    "        for err in high_score_errors:\n",
    "            print(f\"Base(ID={err['base_ID']}, NAME='{err['base_NAME']}')  <->  \"\n",
    "                  f\"Other(ID={err['other_ID']}, NAME='{err['other_NAME']}')  |  score={err['score']}\")\n",
    "\n",
    "    accuracy = 1 - (wrong_matches / total_matches) if total_matches else 1.0\n",
    "    compression_ratio = compress / len(df)\n",
    "    return grouped, accuracy, compression_ratio\n",
    "\n",
    "# 用法示例\n",
    "alternate_names = pd.read_csv('alternate.csv')\n",
    "dedup_result_rows = []\n",
    "groups, acc, compress_ratio = deduplicate_exact_then_fuzzy(primary_names, threshold=90)\n",
    "print(f\"\\n去重准确率（含精确+模糊）: {acc:.4f}\")\n",
    "print(f\"压缩比: {compress_ratio:.4f}\")\n",
    "for group_idx, group in enumerate(groups):\n",
    "    representative = min(group, key=lambda x: len(x['NAME']))\n",
    "    rep_id = representative['ID']\n",
    "    for entry in group:\n",
    "        dedup_result_rows.append({\n",
    "            'original_ID': entry['ID'],\n",
    "            'original_NAME': entry['NAME'],\n",
    "            'group_ID': rep_id,\n",
    "            'group_index': group_idx\n",
    "        })\n",
    "\n",
    "dedup_df = pd.DataFrame(dedup_result_rows)\n",
    "# dedup_df.to_csv('deduplicated_alternate_names.csv', index=False)\n",
    "# print(\"去重结果已保存到 deduplicated_alternate_names.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存所有去重后代表项到 deduplicated_representatives_primary.csv\n"
     ]
    }
   ],
   "source": [
    "representative_rows = []\n",
    "for group in groups:\n",
    "    representative = min(group, key=lambda x: len(x['NAME']))\n",
    "    representative_rows.append({\n",
    "        'ID': representative['ID'],\n",
    "        'NAME': representative['NAME']\n",
    "    })\n",
    "\n",
    "# 保存为 CSV\n",
    "representative_df = pd.DataFrame(representative_rows)\n",
    "representative_df.to_csv('deduplicated_representatives_primary.csv', index=False)\n",
    "print(\"已保存所有去重后代表项到 deduplicated_representatives_primary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
